# -*- coding: utf-8 -*-
"""Image Classifier CIFAR 10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fWk1LWbLZTn8YIBm5z_ik8fCPD5zimdL
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O 

# import backend
import tensorflow as  tf
from keras import backend as K

# Model architecture
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Input,Dense, Dropout, Flatten, Conv2D
from keras.layers import MaxPool2D, Activation, MaxPooling2D
from keras.layers.normalization import BatchNormalization

# Annealer
from keras.callbacks import LearningRateScheduler

# Data processing
from keras.preprocessing.image import ImageDataGenerator, img_to_array
from keras.utils import to_categorical
from keras.preprocessing import image

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Progressor
from tqdm import tqdm
import h5py

from keras.optimizers import Adam

from keras.datasets import cifar10
(x_train_all, y_train_all), (x_test, y_test) = cifar10.load_data()

print("Number of training sample: ",x_train_all.shape[0])
print("Number of test samples: ", x_test.shape[0])

LABEL_NAMES = ['Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

VALIDATION_SIZE = 10000

LABEL_NAMES[y_train_all[10025][0]]

x_train_all = x_train_all /255.0
x_test = x_test /255.0

# split training and validation set.
x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, random_state=0, test_size=0.2)

x_val.shape

x_train.shape

# Convert to One Hot Encoding
from keras.utils import np_utils

y_train_ohe = np_utils.to_categorical(y_train, num_classes=10)
y_test_ohe = np_utils.to_categorical(y_test, num_classes=10)
y_val_ohe = np_utils.to_categorical(y_val, num_classes=10)

print(y_val_ohe)
y_val_ohe.shape

from keras.applications.vgg16 import VGG16
from keras.models import Model
def create_cnn_model():
    image_input = Input(shape=(32, 32, 3))
    
    vgg_model  = VGG16(weights='imagenet',include_top=False, input_tensor=image_input)
    
    flatt = Flatten()(vgg_model.output)
    
    couche1 = Dense(128, activation='relu')(flatt) 
    couche1_normalization = BatchNormalization()(couche1)
    couche1_dropout = Dropout(0.2)(couche1_normalization)
    couche2 = Dense(64, activation='relu')(couche1_dropout)
    couche2_normalization = BatchNormalization()(couche2)
    output = Dense(10, activation='softmax', name='output')(couche2_normalization)     
    model = Model( image_input, output )
    return model

model = create_cnn_model()
model.summary()

model.compile(optimizer='adam', 
              loss='categorical_crossentropy',
                metrics=['accuracy'])

from keras.callbacks import EarlyStopping, ModelCheckpoint
# Use Data Augmentation
datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip= True)
es = EarlyStopping(patience=10, monitor='val_accuracy', mode='max')
mc = ModelCheckpoint('./weights.h5', monitor='val_accuracy', mode='max', save_best_only=True)

model.fit_generator(datagen.flow(x_train, y_train_ohe,batch_size = 32), steps_per_epoch = 1250, epochs=500, validation_data=[x_val, y_val_ohe], callbacks = [es,mc])
# Load The Best weights in the ModelCheckpoint
model.load_weights('./weights.h5')

# Predict The Test
preds = model.predict(x_val)
score_test = accuracy_score( y_val, np.argmax(preds, axis=1) )

print (' The test score : ', score_test)
print('')

_, evaluate = model.evaluate(x_test, y_test_ohe, verbose=1)
print('>%.3f' % (evaluate * 100.0))

prediction = model.predict_classes(test)

